{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Matin Mahmoodkhani - 99522095***\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nb8_j4O-S6Ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q1: Probabilistic N-Gram Language Model(50 points)"
      ],
      "metadata": {
        "id": "a4NQTign_k_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "The objective of this question is to implement and experiment with an N-Gram language model using the Reuters dataset. The task involves building a probabilistic N-Gram model and creating a text generator based on the trained model with customizable parameters.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "\n",
        "**1.Text Preprocessing (5 points):**\n",
        "*   Implement the preprocess_text function to perform necessary text preprocessing. You may use NLTK or other relevant libraries for this task. (Already provided, no modification needed)\n",
        "\n",
        "\n",
        "**2.Build Probabilistic N-Gram Model (15 points):**\n",
        "\n",
        "*   Implement the build_probabilistic_ngram_model function to construct a probabilistic N-Gram model from the Reuters dataset.\n",
        "\n",
        "\n",
        "**3.Generate Text with Customizable Parameters (15 points):**\n",
        "\n",
        "*   Implement the generate_text function to generate text given a seed text and the probabilistic N-Gram model.\n",
        "*   The function should have parameters for probability_threshold and min_length to customize the generation process.\n",
        "*   Ensure that the generation stops when either the specified min_length is reached or the probabilities fall below probability_threshold.\n",
        "\n",
        "\n",
        "**4.Experimentation and Parameter Tuning (5 points):**\n",
        "\n",
        "*   Use Google Colab to experiment with different values of n_value, probability_threshold, and min_length.\n",
        "Find the optimal parameters that result in coherent and meaningful generated text.\n",
        "*   Provide a detailed analysis of the impact of changing each parameter on the generated text's quality.\n",
        "*   Discuss any challenges faced during parameter tuning and propose potential improvements.\n",
        "\n",
        "\n",
        "**5.Results and Conclusion (10 points):**\n",
        "\n",
        "*   Summarize your findings and present the optimal parameter values for n_value, probability_threshold, and min_length.\n",
        "*   Discuss the trade-offs and considerations when selecting these parameters.\n",
        "*   Conclude with insights gained from the experimentation."
      ],
      "metadata": {
        "id": "zDKtnG-HAH1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk import ngrams\n",
        "import random\n",
        "import string\n",
        "from collections import defaultdict\n",
        "\n",
        "# Download the Reuters dataset if not already downloaded\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "3NWXJy-T-Vd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b39ba47-15e0-49c6-fee6-eb96a0384618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Document on functions*\n",
        "\n",
        "\n",
        " **Preprocess_text Function:**\n",
        "this function does some tast on our corpus like making all the alphabets in lowercase and removing punctuations.\n",
        "after that we use nltk tokenizer so that we tokenize every sentence in our corpus.\n",
        "\n",
        "**build_probabilistic_ngram_model:**\n",
        "In this function, we want to make our ngram model. in the input, we get n for the n gram model and also all the texts.\n",
        "\n",
        "first, in a loop we consider every senteces in our corpus. and considering n, we make our model. here we consider n as 3. so that we make the model based on every 3 words that are in a row.\n",
        "after that we calculate the probabilities.\n",
        "\n",
        "we want to find the next word. so we separate every n word that is token to 2 groups. last word and the rest\n",
        "\n",
        "**generate_text:**\n",
        "In the function, first we get the text we want to predict. the we split the text and after the we loop through the model and check for expressions that can complete the text. then we choose the one with the highest probability.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ezwpSdoSw1Ax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9IHxAbU0N80"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Function to build a probabilistic n-gram model\n",
        "def build_probabilistic_ngram_model(corpus, n):\n",
        "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "    for sentence in corpus:\n",
        "        ngrams_in_sentence = list(ngrams(sentence, n, pad_left=True, pad_right=True))\n",
        "        for ngram in ngrams_in_sentence:\n",
        "            prefix = tuple(ngram[:-1])\n",
        "            suffix = ngram[-1]\n",
        "            model[prefix][suffix] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    for prefix in model:\n",
        "        total_count = float(sum(model[prefix].values()))\n",
        "        for suffix in model[prefix]:\n",
        "            model[prefix][suffix] /= total_count\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Function to generate text using the probabilistic n-gram model with stop criteria\n",
        "def generate_text(model, seed_text, n, probability_threshold=0.1, min_length=10):\n",
        "    generated_text = seed_text.lower().split()\n",
        "    current_length = len(generated_text)\n",
        "\n",
        "    while current_length < min_length or (current_length < 100 and random.uniform(0, 1) > probability_threshold):\n",
        "        current_prefix = tuple(generated_text[-n+1:])\n",
        "\n",
        "        # Check if the current_prefix exists in the model\n",
        "        if current_prefix in model:\n",
        "            next_word = max(model[current_prefix].items(), key=lambda x: x[1])[0]\n",
        "            generated_text.append(next_word)\n",
        "            current_length += 1\n",
        "        else:\n",
        "            break  # Break if the current_prefix is not in the model\n",
        "\n",
        "    return ' '.join(generated_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Reuters dataset\n",
        "corpus = [reuters.raw(file_id) for file_id in reuters.fileids()]\n",
        "\n",
        "# Preprocess the entire corpus\n",
        "preprocessed_corpus = [preprocess_text(text) for text in corpus]\n",
        "\n",
        "# Choose an n for the n-gram model\n",
        "n_value = 3  # You may change this value\n",
        "\n",
        "# Build the probabilistic n-gram model\n",
        "probabilistic_ngram_model = build_probabilistic_ngram_model(preprocessed_corpus, n_value)"
      ],
      "metadata": {
        "id": "eVVMe_s59Ngd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the text generator\n",
        "seed_text = \"Inflation is\"\n",
        "generated_text = generate_text(probabilistic_ngram_model, seed_text, n_value, probability_threshold=0.02, min_length=5)\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "id": "n-4WP7IC9Q7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0840b96-2299-4956-ee4f-b49a384e1470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text: inflation is expected to be a major trade bill that would be a major\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Parameters :** After experimenting different values, the n_value may vary depending on the complexity of the language structure in the corpus. In this example, n_value = 3 might be the best option.\n",
        "The probability_threshold parameter controls the likelihood of stopping the generation based on the probability of the next word. The optimal value depends on the randomness and coherence. 0.02 may be the best choice.\n",
        "The min_length parameter defines the minimum length of the generated text. The optimal value depends on the corpus, but 5 is the best one for this example.\n",
        "\n",
        "**trade-offs and considerations :** when choosing the n_order, we should make the a balance between randomness and coherence. if it is too small we would have more randomness and less coherence. considering it so big also would be the opposite.\n",
        "probability_threshold is also the same. considering it too small or too large may result in bad results. The trade-off is between diversity and coherence.\n",
        "Setting min_length low might generate very short text and Setting it high may limit the diversity of the generated text.\n",
        "\n",
        "**Insights :** having more texts for learning the algorithm, will result in having a better model. after that, setting best values for our parameters are also very important for us."
      ],
      "metadata": {
        "id": "PXn4cqVd5nEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q2: Sentiment Analysis with Naive Bayes Classifier(50 Points)"
      ],
      "metadata": {
        "id": "dZ3XzDx7JUNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "You are tasked with implementing a Naive Bayes classifier for sentiment analysis. The provided code is incomplete, and your goal is to complete the missing parts. Additionally, you should train the classifier on a small dataset and analyze its performance.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1.**Complete the Code (35 points)**: Fill in the missing parts in the provided Python code for the Naive Bayes classifier. Pay special attention to the `extract_features` function.\n",
        "\n",
        "2.**Train and Test**: Train the Naive Bayes classifier on the training data and test it on a separate test set. Evaluate the accuracy of the classifier.\n",
        "\n",
        "3.**Analysis (15 points)**: Discuss the results. Identify any misclassifications and try to understand why the classifier may fail in those cases. Provide examples of sentences that were not predicted correctly and explain possible reasons.\n"
      ],
      "metadata": {
        "id": "NMuVkjW2XfAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import string\n",
        "from collections import defaultdict\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import movie_reviews\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "M68XJubdKeDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b644c261-f30b-4f10-d5df-cb7656088905"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(tokens):\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Perform stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "KSLo4_JoUcax"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, classes):\n",
        "        self.classes = classes\n",
        "        self.class_probs = defaultdict(float)\n",
        "        self.feature_probs = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "    def train(self, training_data):\n",
        "        # Implement training here\n",
        "        # You should use get_features function to extract useful tokens from dataset and use them to train the classifier.\n",
        "\n",
        "        # Here, first we compute count of positive and negative data\n",
        "        class_counts = defaultdict(int)\n",
        "        for _, sentiment in training_data:\n",
        "            class_counts[sentiment] += 1\n",
        "\n",
        "        # Then, we calculate class probabilities based on count of each class\n",
        "        total_examples = len(training_data)\n",
        "        for sentiment in self.classes:\n",
        "            self.class_probs[sentiment] = class_counts[sentiment] / total_examples\n",
        "\n",
        "        # After that, we create a new dict and inside it, we get all the features that are used in the corpus\n",
        "        # then, we calculate count of appearencing in the corpus based on their negative or positive sentiment.\n",
        "        # for example word \"taken\" may be used 3 times in the texts with positive sentiment and 1 time with negative sentiment\n",
        "        # so the dict would be like this: feature_counts = {\"taken\" : {\"pos\" : 3, \"neg\" : 1}}\n",
        "        feature_counts = defaultdict(lambda: defaultdict(int))\n",
        "        for tokens, sentiment in training_data:\n",
        "            features = get_features(tokens)\n",
        "            for feature in features:\n",
        "                feature_counts[feature][sentiment] += 1\n",
        "\n",
        "        # using the dict above, we calculate every feature probability based on being negative or positive\n",
        "        for feature in feature_counts:\n",
        "            total = sum(feature_counts[feature].values())\n",
        "            for sentiment in self.classes:\n",
        "                self.feature_probs[feature][sentiment] = feature_counts[feature][sentiment] / total\n",
        "\n",
        "\n",
        "    def classify(self, features):\n",
        "        # Implement classification here\n",
        "        # first we define 2 variables that save the best case for them\n",
        "        # after that for each sentiment, we go through the features of the text and check for their probability based on the feature_probs dict\n",
        "        # also we check that feature exists in the dict. then, we add its log to probability.\n",
        "        # note that we consider probability of the sentiment from results of the training\n",
        "        max_prob = float('-inf')\n",
        "        best_class = None\n",
        "        for sentiment in self.classes:\n",
        "            prob = math.log(self.class_probs[sentiment])\n",
        "            for feature in features:\n",
        "                prob += math.log(self.feature_probs[feature][sentiment] + 1e-10)\n",
        "            if prob > max_prob:\n",
        "                max_prob = prob\n",
        "                best_class = sentiment\n",
        "\n",
        "        return best_class"
      ],
      "metadata": {
        "id": "m2Whvjy_Jq8n"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the movie reviews dataset from NLTK\n",
        "data = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "# data that we are tokenized\n",
        "random.shuffle(data)\n",
        "\n",
        "# Shuffle the dataset for randomness\n",
        "random.shuffle(data)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(data) * split_ratio)\n",
        "train_set = data[:split_index]\n",
        "test_set = data[split_index:]\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "classes = set(sentiment for _, sentiment in train_set)\n",
        "classifier = NaiveBayesClassifier(classes)\n",
        "classifier.train(train_set)\n",
        "\n",
        "\n",
        "def calculate_accuracy(dataset, dataset_type):\n",
        "    # Test the classifier on the testing set\n",
        "    correct_predictions = 0\n",
        "    for example in dataset:\n",
        "        tokens, true_sentiment = example\n",
        "        features = get_features(tokens)\n",
        "        predicted_sentiment = classifier.classify(features)\n",
        "        if predicted_sentiment == true_sentiment:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / len(dataset)\n",
        "    print(f\"{dataset_type} Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "calculate_accuracy(train_set, 'Train')\n",
        "calculate_accuracy(test_set, 'Test')"
      ],
      "metadata": {
        "id": "j2jeyI6nKooE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3bde8d-cc81-4bd8-a13a-072c353ce64a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9975\n",
            "Test Accuracy: 0.705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis :**\n",
        "\n",
        "In the exercise, we make a classifier for finding if a sentence is positive or negative. So, we built a class and added to functions to it. explanations of each function is written beside it in the code and can be easily underestood.\n",
        "\n",
        "First we made a dictionary of all features based on the training set. then, calculate probability of each feature in negative or positive cases.\n",
        "\n",
        "consider the word \"High\", high has been used 6 times in the positive texts and 4 in the negative sentences. So in our dictionary, it would have a probability like this: { \"High\" : {\"pos\" : 0.6, \"neg\" : 0.4}}. other words are the same. in the classification part, we use these numbers and math.log to calculate the probability for every sentiment and finally we choose the best option for it.\n",
        "\n",
        "I've test the classifier using different sizes of the training tests. Usually having the more training examples would give us the more accurate probabilities and also list of our features increases. So, that would help us a lot to increase our accuracy.\n",
        "\n",
        "It may be intresting to find out that why our training accuracy is not 100%. that is because in some cases, there are multiple words that are used in the sentence with the opposite meaning from their usual meaning. for example word \"bad\" is a negative word. But maybe it is used in a positive sentence and while testing, these words may affect the probability and consider that a text is positive while it is negative acually.\n",
        "\n",
        "In the test part, we could get 70.5% accuracy which is not bad but can be better with having more training examples. For example, if the split ratio changes to 0.9, our testing accuracy may be higher as 71.5% which is more than before.\n",
        "\n",
        "Because the examples are too long, we can't represent a texts that is classified wrong. but we can say some reasons for misclassification:\n",
        "\n",
        "1. some texts are too complex and words are getting the wrong sentiment.\n",
        "2. there may be words that are not in the training example.\n",
        "\n"
      ],
      "metadata": {
        "id": "nDb1-dYbNna-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submission Instructions:\n"
      ],
      "metadata": {
        "id": "Nfl8UA42Gqjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "3.Clearly present the results of your parameter tuning in the notebook.\n",
        "\n",
        "4.Provide a brief summary of your findings and insights in the conclusion section.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Experiment with various seed texts to showcase the diversity of generated text.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ],
      "metadata": {
        "id": "75kVTQX6GsCn"
      }
    }
  ]
}